{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPuNQqmxWy9saczgdVEqWub",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2403a54075-dot/NLP_BT-03_4075/blob/main/Lab_Assignment_2\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A8Y3hfCfWdiC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ac57e0ed",
        "outputId": "72a8058e-34ea-45f4-f24d-32cd384d2e9f"
      },
      "source": [
        "# Install NLTK and spaCy\n",
        "!pip install nltk spacy\n",
        "!python -m spacy download en_core_web_sm"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.12/dist-packages (3.8.11)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.3)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2025.11.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.15)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.13)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (8.3.10)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.5.2)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.4.3)\n",
            "Requirement already satisfied: typer-slim<1.0.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.20.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.32.4)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.12.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.41.4)\n",
            "Requirement already satisfied: typing-extensions>=4.14.1 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.11.12)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.3)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.4.2->spacy) (0.23.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.4.2->spacy) (7.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->spacy) (3.0.3)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.4.2->spacy) (2.0.1)\n",
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m109.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "904b55cc"
      },
      "source": [
        "Next, let's define a sample medical text corpus for demonstration purposes. In a real-world scenario, you would load this from a file or database."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfe323b5",
        "outputId": "639500cd-2bd7-452d-c6ba-3e4f2210de9d"
      },
      "source": [
        "import nltk\n",
        "import spacy\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "\n",
        "# Download necessary NLTK data\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('punkt_tab') # Added to resolve LookupError for Punkt tokenizer\n",
        "\n",
        "# Load spaCy model\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "# Sample medical text corpus\n",
        "medical_text = \"\"\"The patient presented with a high fever, persistent cough, and severe headaches. Diagnosed with influenza, antiviral medications were prescribed. Follow-up appointments are scheduled to monitor recovery and prevent complications. Early detection is crucial for managing infectious diseases effectively.\"\"\"\n",
        "\n",
        "print(\"Original Medical Text:\")\n",
        "print(medical_text)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Medical Text:\n",
            "The patient presented with a high fever, persistent cough, and severe headaches. Diagnosed with influenza, antiviral medications were prescribed. Follow-up appointments are scheduled to monitor recovery and prevent complications. Early detection is crucial for managing infectious diseases effectively.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18a9a2be"
      },
      "source": [
        "## 1. Tokenization using NLTK\n",
        "\n",
        "Tokenization is the process of breaking down text into smaller units like sentences (sentence tokenization) or words (word tokenization)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88f1b106",
        "outputId": "dcc71ca4-9151-4e51-ed12-c7a4fdc0c2f8"
      },
      "source": [
        "# Sentence Tokenization with NLTK\n",
        "sentences_nltk = sent_tokenize(medical_text)\n",
        "print(\"NLTK Sentence Tokenization:\")\n",
        "for i, sent in enumerate(sentences_nltk):\n",
        "    print(f\"Sentence {i+1}: {sent}\")\n",
        "\n",
        "# Word Tokenization with NLTK\n",
        "words_nltk = word_tokenize(medical_text)\n",
        "print(\"\\nNLTK Word Tokenization (first 20 words):\")\n",
        "print(words_nltk[:20])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NLTK Sentence Tokenization:\n",
            "Sentence 1: The patient presented with a high fever, persistent cough, and severe headaches.\n",
            "Sentence 2: Diagnosed with influenza, antiviral medications were prescribed.\n",
            "Sentence 3: Follow-up appointments are scheduled to monitor recovery and prevent complications.\n",
            "Sentence 4: Early detection is crucial for managing infectious diseases effectively.\n",
            "\n",
            "NLTK Word Tokenization (first 20 words):\n",
            "['The', 'patient', 'presented', 'with', 'a', 'high', 'fever', ',', 'persistent', 'cough', ',', 'and', 'severe', 'headaches', '.', 'Diagnosed', 'with', 'influenza', ',', 'antiviral']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f46b2196"
      },
      "source": [
        "## 2. Stemming and Lemmatization using NLTK\n",
        "\n",
        "**Stemming** is a crude heuristic process that chops off the ends of words in the hope of achieving a base form.\n",
        "\n",
        "**Lemmatization** is a more sophisticated process that uses vocabulary and morphological analysis of words to return the base or dictionary form of a word, known as the lemma."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ddcfc15",
        "outputId": "54ad43ff-d331-4797-de62-14d3a714b943"
      },
      "source": [
        "# Stemming with NLTK's Porter Stemmer\n",
        "porter = PorterStemmer()\n",
        "stemmed_words_nltk = [porter.stem(word) for word in words_nltk]\n",
        "print(\"NLTK Stemming (first 20 words):\")\n",
        "print(stemmed_words_nltk[:20])\n",
        "\n",
        "# Lemmatization with NLTK's WordNet Lemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "lemmatized_words_nltk = [lemmatizer.lemmatize(word) for word in words_nltk]\n",
        "print(\"\\nNLTK Lemmatization (first 20 words):\")\n",
        "print(lemmatized_words_nltk[:20])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NLTK Stemming (first 20 words):\n",
            "['the', 'patient', 'present', 'with', 'a', 'high', 'fever', ',', 'persist', 'cough', ',', 'and', 'sever', 'headach', '.', 'diagnos', 'with', 'influenza', ',', 'antivir']\n",
            "\n",
            "NLTK Lemmatization (first 20 words):\n",
            "['The', 'patient', 'presented', 'with', 'a', 'high', 'fever', ',', 'persistent', 'cough', ',', 'and', 'severe', 'headache', '.', 'Diagnosed', 'with', 'influenza', ',', 'antiviral']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a16d7ecf"
      },
      "source": [
        "## 3. Tokenization, Lemmatization, and Parts-of-Speech Tagging using spaCy\n",
        "\n",
        "spaCy provides an integrated pipeline for tokenization, lemmatization, and other NLP tasks. It's generally preferred for production-level NLP tasks due to its speed and accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bfa5003",
        "outputId": "ebe987ad-af14-4f2e-aef2-d2f45ba3ed20"
      },
      "source": [
        "# Process text with spaCy\n",
        "doc = nlp(medical_text)\n",
        "\n",
        "# Tokenization with spaCy\n",
        "print(\"spaCy Tokenization:\")\n",
        "for token in doc:\n",
        "    print(f\"Text: {token.text}, Lemma: {token.lemma_}, POS: {token.pos_}, Is Stop: {token.is_stop}\")\n",
        "\n",
        "# Extracting sentences with spaCy\n",
        "sentences_spacy = [sent.text for sent in doc.sents]\n",
        "print(\"\\nspaCy Sentence Tokenization:\")\n",
        "for i, sent in enumerate(sentences_spacy):\n",
        "    print(f\"Sentence {i+1}: {sent}\")\n",
        "\n",
        "# Extracting words and lemmas with spaCy\n",
        "words_spacy = [token.text for token in doc]\n",
        "lemmas_spacy = [token.lemma_ for token in doc]\n",
        "\n",
        "print(\"\\nspaCy Word Tokenization (first 20 words):\")\n",
        "print(words_spacy[:20])\n",
        "print(\"\\nspaCy Lemmatization (first 20 words):\")\n",
        "print(lemmas_spacy[:20])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "spaCy Tokenization:\n",
            "Text: The, Lemma: the, POS: DET, Is Stop: True\n",
            "Text: patient, Lemma: patient, POS: NOUN, Is Stop: False\n",
            "Text: presented, Lemma: present, POS: VERB, Is Stop: False\n",
            "Text: with, Lemma: with, POS: ADP, Is Stop: True\n",
            "Text: a, Lemma: a, POS: DET, Is Stop: True\n",
            "Text: high, Lemma: high, POS: ADJ, Is Stop: False\n",
            "Text: fever, Lemma: fever, POS: NOUN, Is Stop: False\n",
            "Text: ,, Lemma: ,, POS: PUNCT, Is Stop: False\n",
            "Text: persistent, Lemma: persistent, POS: ADJ, Is Stop: False\n",
            "Text: cough, Lemma: cough, POS: NOUN, Is Stop: False\n",
            "Text: ,, Lemma: ,, POS: PUNCT, Is Stop: False\n",
            "Text: and, Lemma: and, POS: CCONJ, Is Stop: True\n",
            "Text: severe, Lemma: severe, POS: ADJ, Is Stop: False\n",
            "Text: headaches, Lemma: headache, POS: NOUN, Is Stop: False\n",
            "Text: ., Lemma: ., POS: PUNCT, Is Stop: False\n",
            "Text: Diagnosed, Lemma: diagnose, POS: VERB, Is Stop: False\n",
            "Text: with, Lemma: with, POS: ADP, Is Stop: True\n",
            "Text: influenza, Lemma: influenza, POS: NOUN, Is Stop: False\n",
            "Text: ,, Lemma: ,, POS: PUNCT, Is Stop: False\n",
            "Text: antiviral, Lemma: antiviral, POS: ADJ, Is Stop: False\n",
            "Text: medications, Lemma: medication, POS: NOUN, Is Stop: False\n",
            "Text: were, Lemma: be, POS: AUX, Is Stop: True\n",
            "Text: prescribed, Lemma: prescribe, POS: VERB, Is Stop: False\n",
            "Text: ., Lemma: ., POS: PUNCT, Is Stop: False\n",
            "Text: Follow, Lemma: follow, POS: VERB, Is Stop: False\n",
            "Text: -, Lemma: -, POS: PUNCT, Is Stop: False\n",
            "Text: up, Lemma: up, POS: ADP, Is Stop: True\n",
            "Text: appointments, Lemma: appointment, POS: NOUN, Is Stop: False\n",
            "Text: are, Lemma: be, POS: AUX, Is Stop: True\n",
            "Text: scheduled, Lemma: schedule, POS: VERB, Is Stop: False\n",
            "Text: to, Lemma: to, POS: PART, Is Stop: True\n",
            "Text: monitor, Lemma: monitor, POS: VERB, Is Stop: False\n",
            "Text: recovery, Lemma: recovery, POS: NOUN, Is Stop: False\n",
            "Text: and, Lemma: and, POS: CCONJ, Is Stop: True\n",
            "Text: prevent, Lemma: prevent, POS: VERB, Is Stop: False\n",
            "Text: complications, Lemma: complication, POS: NOUN, Is Stop: False\n",
            "Text: ., Lemma: ., POS: PUNCT, Is Stop: False\n",
            "Text: Early, Lemma: early, POS: ADJ, Is Stop: False\n",
            "Text: detection, Lemma: detection, POS: NOUN, Is Stop: False\n",
            "Text: is, Lemma: be, POS: AUX, Is Stop: True\n",
            "Text: crucial, Lemma: crucial, POS: ADJ, Is Stop: False\n",
            "Text: for, Lemma: for, POS: ADP, Is Stop: True\n",
            "Text: managing, Lemma: manage, POS: VERB, Is Stop: False\n",
            "Text: infectious, Lemma: infectious, POS: ADJ, Is Stop: False\n",
            "Text: diseases, Lemma: disease, POS: NOUN, Is Stop: False\n",
            "Text: effectively, Lemma: effectively, POS: ADV, Is Stop: False\n",
            "Text: ., Lemma: ., POS: PUNCT, Is Stop: False\n",
            "\n",
            "spaCy Sentence Tokenization:\n",
            "Sentence 1: The patient presented with a high fever, persistent cough, and severe headaches.\n",
            "Sentence 2: Diagnosed with influenza, antiviral medications were prescribed.\n",
            "Sentence 3: Follow-up appointments are scheduled to monitor recovery and prevent complications.\n",
            "Sentence 4: Early detection is crucial for managing infectious diseases effectively.\n",
            "\n",
            "spaCy Word Tokenization (first 20 words):\n",
            "['The', 'patient', 'presented', 'with', 'a', 'high', 'fever', ',', 'persistent', 'cough', ',', 'and', 'severe', 'headaches', '.', 'Diagnosed', 'with', 'influenza', ',', 'antiviral']\n",
            "\n",
            "spaCy Lemmatization (first 20 words):\n",
            "['the', 'patient', 'present', 'with', 'a', 'high', 'fever', ',', 'persistent', 'cough', ',', 'and', 'severe', 'headache', '.', 'diagnose', 'with', 'influenza', ',', 'antiviral']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5a7e8bc"
      },
      "source": [
        "## 4. Comparison of Outputs and Why Lemmatization is Critical in Healthcare NLP\n",
        "\n",
        "Let's compare the outputs from stemming and lemmatization and then discuss why lemmatization is particularly critical in healthcare NLP.\n",
        "\n",
        "From the outputs, you can observe the following:\n",
        "\n",
        "*   **NLTK Stemming:**\n",
        "    *   `'patient'` -> `'patient'` (same)\n",
        "    *   `'presented'` -> `'present'` (lost past tense nuance, but still a valid word)\n",
        "    *   `'persistent'` -> `'persist'` (a verb form, not the adjective)\n",
        "    *   `'headaches'` -> `'headach'` (not a valid English word)\n",
        "    *   `'severe'` -> `'sever'` (a different word with a different meaning)\n",
        "    *   `'Diagnosed'` -> `'diagnos'` (not a valid English word)\n",
        "    *   `'antiviral'` -> `'antivir'` (not a valid English word)\n",
        "\n",
        "*   **NLTK Lemmatization:**\n",
        "    *   `'The'` -> `'The'`\n",
        "    *   `'patient'` -> `'patient'`\n",
        "    *   `'presented'` -> `'presented'` (NLTK's WordNet Lemmatizer often requires POS tags for better results, defaulting to noun if not provided, thus 'presented' is kept as is here)\n",
        "    *   `'persistent'` -> `'persistent'` (similar to 'presented', POS tagging would help)\n",
        "    *   `'cough'` -> `'cough'`\n",
        "    *   `'headaches'` -> `'headache'` (correct base form, valid word)\n",
        "    *   `'Diagnosed'` -> `'Diagnosed'` (similar to 'presented')\n",
        "    *   `'antiviral'` -> `'antiviral'` (correct base form, valid word)\n",
        "\n",
        "*   **spaCy Lemmatization (which is generally more robust due to its integrated POS tagging):**\n",
        "    *   `'The'` -> `'the'`\n",
        "    *   `'patient'` -> `'patient'`\n",
        "    *   `'presented'` -> `'present'` (correctly identifies verb lemma)\n",
        "    *   `'persistent'` -> `'persistent'`\n",
        "    *   `'cough'` -> `'cough'`\n",
        "    *   `'headaches'` -> `'headache'`\n",
        "    *   `'Diagnosed'` -> `'diagnose'` (correctly identifies verb lemma)\n",
        "    *   `'antiviral'` -> `'antiviral'`\n",
        "\n",
        "### Why Lemmatization is Critical in Healthcare NLP:\n",
        "\n",
        "1.  **Precision and Accuracy:** In healthcare, ambiguous or incorrect terms can have severe consequences. Stemming often chops off word endings heuristically, sometimes resulting in non-dictionary words (like `headach` or `diagnos`). Lemmatization, by contrast, uses vocabulary and morphological analysis to return the *base or dictionary form (lemma)* of a word, ensuring that the resulting term is a valid word and retains its meaning. This precision is crucial for correct interpretation of clinical text.\n",
        "\n",
        "2.  **Standardization of Medical Terminology:** Medical records and research papers contain highly specialized and often complex terminology. Different inflections of a medical term (e.g., 'diagnose', 'diagnosed', 'diagnosing'; 'infection', 'infectious', 'infected') should ideally map to a single canonical form for consistent analysis. Lemmatization achieves this standardization more effectively than stemming, which might produce disparate or unrecognizable 'stems'. This is vital for tasks like building clinical ontologies, coding medical events, or linking to standardized medical vocabularies (e.g., SNOMED CT, ICD-10).\n",
        "\n",
        "3.  **Improved Information Retrieval:** When searching electronic health records (EHRs) or medical literature, a search query that has been lemmatized (e.g., searching for 'treat' instead of 'treating', 'treats', 'treated') will yield more comprehensive and accurate results by matching all inflected forms of the term.\n",
        "\n",
        "4.  **Enhanced Machine Learning Models:** For training NLP models on medical data (e.g., for disease classification, adverse drug event detection, or named entity recognition), having consistent input features is paramount. Lemmatized words provide a cleaner, more semantically coherent feature set, leading to better model generalization and performance compared to stemmed words, which can introduce noise with their non-dictionary forms.\n",
        "\n",
        "5.  **Contextual Understanding:** Lemmatization, especially with tools like spaCy that integrate Part-of-Speech (POS) tagging, can differentiate between words that are spelled the same but have different meanings or grammatical roles (e.g., 'monitor' as a noun vs. a verb). This contextual understanding is often vital in medical text where subtle distinctions can change the meaning of a clinical statement.\n",
        "\n",
        "In summary, while stemming is faster, lemmatization's ability to provide linguistically valid base forms that retain semantic meaning makes it indispensable for the high-stakes, precision-dependent environment of healthcare NLP."
      ]
    }
  ]
}